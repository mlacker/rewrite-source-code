# MySQL

MySQL 是一个单进程多线程架构的数据库，MySQL 数据库实例在操作系统上表现就是一个进程。

MySql 是插件式存储引擎，它是基于表的，而不是数据库。常用的存储引擎如下：

- InnoDB
- MyISAM
  - 不支持事务
  - 缓冲池只缓存索引文件，不缓存数据文件
  - 由 MYD 和 MYI 文件组成，分别存放数据文件和索引文件
- 此外还有 NDB, Memory, Archive, Marai 等存储引擎

### Join

#### Nested-Loop Join Algorithm

嵌套循环算法处理表连接。

#### Block Nested-Loop Join Algorithm

如果 Join 条件**没有使用索引**，就会采用 BNLJ，缓冲在外部循环中读取的行到 Join buffer 中，以减少必须读取内部循环的表的次数。

#### Hash Join

从 MySQL 8.0.18 开始，对任何查询都具有相等连接条件且**不使用索引**的查询使用哈希连接。

EXPLAIN 查询计划中 Extra 列可以看到 Using join buffer (hash join)

## InnoDB

InnoDB 是基于磁盘的存储引擎，而真正数据处理的过程是发生在内存中的，如果是处理写入或修改请求的话，还需要把内存中的内容刷新到磁盘上。所以 InnoDB 将数据划分为若干页，一次最少从磁盘中读取一页数据到内存中，或从内存刷新到磁盘上。

### Page

InnoDB 以**页（Page）**作为磁盘和内存之间交互的基本单位，默认页的大小为 **16KB**。InnoDB 为了不同的目的把**页**分为不同的类型，其中用于存放记录的页也称为**数据页**。

#### 数据页

![数据页结构示意图](https://mmbiz.qpic.cn/mmbiz_png/RLmbWWew55FusCptW3JwBoBchTsR6PJ5YoHfS02chsR4bSERrblH0ousvlric9BV3QcGrCClQ7qibWVWWhx5hQaA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在页的7个组成部分中，我们自己存储的记录会按照我们指定的行格式存储到User Records部分。但是在一开始生成页的时候，其实并没有User Records这个部分，每当我们插入一条记录，都会从Free Space部分，也就是尚未使用的存储空间中申请一个记录大小的空间划分到User Records部分，当Free Space部分的空间全部被User Records部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新的页了

#### 行格式

数据通常是以记录为单位向表中插入的，这些记录在磁盘上的存放方式也被称为行格式。

目前 InnoDB 提供四种行格式，分别是：

- Compact
- Redundant
- Dynamic
- Compressed

MySQL 对一条记录占用的最大存储空间是有限制的，除了 BLOB 或者 TEXT 类型的列之外，其它所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节。
除了列本身的数据之外，还包括 NULL 标识，占用字节的长度。

在 Compact 和 Reduntant 行格式中，对于占用存储空间非常大的列，**只会存储该列的前 768 个字节的数据和一个指向其它页的地址**，然后把剩下的数据存放到其它也中，这个过程也叫做行溢出。

##### Compact

![Compact 行格式示意图](https://mmbiz.qpic.cn/mmbiz_png/RLmbWWew55FVTOrSL5huibzeawNtia5ey37MIoP0YPpYdY7Y0TO0iaZ3a79QB7GiaHyTqJTicNBQ6Nk202h4JECicib3A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

一条完整的记录其实可以被分为**行记录的额外信息**和**记录的真实数据**两大部分。

###### 额外信息

这部分信息是服务器为了描述这条记录而不得不额外添加的一些信息，分别是变长字段长度列表、NULL 值列表和记录头信息。

变长字段长度列表把所有变长类型的列的长度都存放在记录的开头部位形成一个列表，按照列的顺序逆序存放。
列表中只存储非 NULL 的列内容占用的长度，值为 NULL 的列的长度是不存储的。

NULL 值列表通过二进制列表保存数据中值为 NULL 的列，逆序存放。

记录头信息由固定的5个字节组成，详细信息如下表：

| 名称 | bit 位 | 描述 |
| --- | :--: | --- |
| 预留位 | 2 | 没有使用 |
| delete_mask | 1 | 标记该记录是否被删除 |
| min_rec_mask | 1 | 是否位 B+Tree 的非叶子节点中的最小记录 |
| n_owned | 4 | 表示当前槽管理的记录数 |
| heap_no | 13 | 表示当前记录在记录堆的位置信息 |
| record_type | 3 | 记录类型，0 普通记录，1 B+树非叶节点记录，2 最小记录，3 最大记录 |
| next_record | 16 | 下一条记录的相对位置 |

###### 真实数据

除了我们插入的列数据，MySQL 会为每条记录默认的添加一些列（隐藏列），具体如下：

| 列名 | 占用空间（byte） | 是否必须 | 描述 |
| --- | --- | --- | --- |
| row_id | 6 | 否 | 没有主键的时候才会添加，作为主键 |
| transaction_id | 6 | 是 | 事务 ID |
| roll_pointer | 6 | 是 | 回滚指针 |

##### Redundant

![Redundant 行格式示意图](https://mmbiz.qpic.cn/mmbiz_png/RLmbWWew55FVTOrSL5huibzeawNtia5ey3sTj2WHp0xqwYqgadiblaPIXIazt08Hia6Ns8qzlhkDN2Tr5HV6gdvEIw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

Redundant 行格式会把该条记录的所有列的长度都按照逆序存储到字段长度偏移列表。
与 Compact 不同，没有 Null值列表，在头信息存储记录中列的数量。

##### Dynamic, Compressed

MySQL 5.7 默认的行格式是 Dynamic

Dynamic 和 Compressed 行格式与 Compact 非常相像，只不过在处理行溢出数据不同，它们不会存储字符串的前 768 个字节，而是把所有字节都存储到其它页面中，只在记录中存储其它页的地址。

Compressed 会把存储在其它页的数据采用压缩算法进行压缩，以节省空间。

### 内存池

- 维护所有进程/线程需要使用的多个内部数据结构
- 缓存磁盘上的数据，方便快速读取，同时对磁盘文件数据修改之前在这里缓存
- Redo 日志缓存

InnoDB 内存池主要有以下部分

![InnoDB Buffer Pool](https://pic2.zhimg.com/v2-210d508df6c12e9df71982754ee3225d_r.jpg)

#### 缓冲池

InnoDB 是基于磁盘存储的，并将其中的记录按照页的方式进行管理。
而缓冲池就是一块内存区域，主要缓冲数据页和索引页。
InnoDB 中对页的读取操作，首先判断该页是否在缓冲池中，若在，直接读取该页，若不在则从磁盘读取页数据，并存放在缓冲池中。
对页的修改操作，首先修改在缓冲池中的页，再以一定的频率（Checkpoint 机制）刷新到磁盘。

缓冲池通过 LRU（Latest Recent Used，最近最少使用）算法进行管理。最频繁使用的页在 LRU 队列顶端，最少使用的页在尾端，当缓冲池不能存放新读取的页时，首先释放 LRU 队列尾端的页（页数据刷新到磁盘，并从缓冲池中删除）。
InnoDB 对于新读取的页，不是放到 LRU 队列的最前端，而是放到 midpoint 位置（默认为 5/8 处）。这是因为一些 SQL 操作会访问大量的页（如全表扫描），读取大量非热点数据，如果直接放到首部，可能导致真正的热点数据被溢移除。

#### Checkpoint

InnoDB 对于 DML 语句操作，事务提交时只需要在缓冲池中完成操作，然后再通过 Checkpoint 将修改后的脏页数据刷新到磁盘。

InnoDB 有两种 Checkpoint

- Sharp Checkpoint：数据库关闭时将所有脏页刷新到磁盘
- Fuzzy Checkpoint：
  - Master Thread Checkpoint
  Master Thread 每 1s 或 10s 按一定比例将缓冲池的脏页列表刷新到磁盘
  - Flush LRU List Checkpoint
  Page Cleaner 线程发现 LRU 列表中可用页数少于 innodb_lru_scan_depth(1024)，就将 LRU 列表尾端移除，如果这些页中有脏页，就需要 Checkpoint
  - Async/Sync Flush Checkpoint
  重做日志文件空间不可用时，将一部分脏页刷新到磁盘。
  - Dirty Page too much Checkpoint
  脏页数量太多（超过比例 innodb_max_dirty_pages_pct=75），执行 Checkpoint

#### 重做日志

重做日志是为了保证事务的原子性，持久性。InnoDB 采用 Write Ahread Log 策略，事务提交时，先写重做日志，在修改页。数据库宕机重启时通过执行重做日志回复数据。
因为 Checkpoint 之前的页都刷新到磁盘了，只需要执行最新一次 Checkpoint 后的重做日志进行恢复。

InnoDB 中的重做日志是循环使用的，当页被 Checkpoint 刷新到磁盘后，其空间就可以被覆盖重用。如果待写入的空间不可用（脏页还没有刷新到磁盘），就需要强制产生 Checkpoint，将缓冲池中的页至少刷新到当前重做日志的位置。

### 线程

主要作用：

- 负责刷新内存池中的数据，保证缓冲池的内存缓冲的是最新的数据
- 已修改的数据文件刷新到磁盘文件
- 保证数据库发生异常情况下 InnoDB 能恢复到正常状态

InnoDB 运行时主要有以下线程

- Master Thread
  负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性。包括脏页的刷新，合并插入缓冲（Insert buffer），UNDO 页的回收等
- IO Thread
  负责 AIO 请求的回调处理
- Purge Thread
  事务提交后，undo log 可能不再需要，由 Purge Thread 负责回收并重新分配的这些已经使用的 undo 页。
- Page Cleaner Thread
  将 Master Thread 中刷新脏页的工作移至该线程。

### InnoDB关键特性

#### 自适应哈希索引

InnoDB会监控对表上各索引页的查询执行情况，如发现建立哈希索引可以提升速度，则建立哈希索引，这是过程不需要用户干预。

#### 异步IO

InnoDB使用异步IO操作磁盘，避免同步IO导致阻塞，也可以进行IO Merge操作，将多个IO操作合并为一个IO操作。

#### 刷新邻接页

当刷新一个脏页时，InnoDB会检测该页所在区的所有页，如果是脏页，一起刷新，这是可以通过AIO将多个IO写入操作合并为一个IO操作。

## Page

## B+Tree

## InnoDB Buffer

### InnoDB 关键特性

#### 插入缓冲

插入聚集索引一般是顺序的，不需要磁盘的随机读取
但插入非聚集索引叶子节点不是顺序的，需要离散访问非聚集索引页，速度较慢。
对于非聚集索引的插入或更新，先判断插入的非聚集索引页是否在缓存池中，若在，直接插入，或不在，先放到一个Inser Buffer对象中，
然后根据一些算法将Insert Buffer缓存的记录通过后台线程慢慢合并刷新回辅助索引。
插入缓冲将多次插入合并为一次操作，减少磁盘的离散操作。

使用Insert Buffer需满足两个条件：
索引是辅助索引
索引不是唯一的（不需要查找索引页判断唯一性）

#### 两次写 doublewrite

部分写失效：页数据写入到磁盘时只写了一部分（如16K数据只写了2K），数据库就宕机了，导致页数据损坏，这时无法使用重做日志恢复。（执行重做日志时需要利用页的一些变量，如checksum）

因此在使用重做日志恢复数据库，需要有一个页的副本，当发生写失效时，先通过页的副本还原该页，再进行重做。于是InnoDB实现了doublewrite技术。

## Redo log

记录事务执行后的状态，用来恢复未写入磁盘的数据（data file）的已成功事务更新的数据。

顺序写入磁盘性能较快，用于故障后恢复。保障了事务的持久性。

log buffer 刷入磁盘后，才提交事务。

## Undo log

用于记录事务开始前的状态，用于事务失败时的回滚操作。

用于实现 MVCC，保障了事务的原子性（回滚）。

## Binlog

用于**主从复制**，从库利用主库上的 binlog 进行重播。
用于数据库的基于时间点的还原。

#### redo log & binlog 二阶段提交

通过两阶段提交过程来完成事务的一致性，理论上时先写 redo log，再写 binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。

redo log 刷入磁盘后，将回滚段置为 prepared 状态。

innodb 释放锁，释放回滚段，设置 redo log 的提交状态，binlog 持久化到磁盘。

## MVCC

Multi-Version Concurrency Control 即多版本并发控制，是为了提高数据库并发性能，用更好的方式去处理读-写冲突，即使有读写冲突时，也能非阻塞并发读。

数据库并发操作分为三种情况：

- 读-读：不存在任何问题，也不需要并发控制
- 读-写：有线程安全问题，可能会造成事务隔离性问题，如脏读、幻读、不可重复读
- 写-写：有线程安全问题，可能会造成覆盖更新、更新丢失的问题，通过互斥锁解决

MVCC 是一种用来解决**读-写冲突**的无锁并发控制，这个读指的是**快照读**，而非**当前读**。

- 当前读（锁定读）
  像 SELECT LOCK IN SHARE MODE（共享锁）, SELECT FOR UPDATE, INSERT, UPDATE, DELETE（排他锁）这些操作都是当前读，就是它读取的是记录的最新版本，还要保证其它并发事务不能修改当前记录，会对读取的记录进行加锁。
- 快照读
  像 SELECT 操作就是快照读，即不加锁的非阻塞读（串行隔离级别会退化成当前读）。快照读的实现是基于多版本并发控制，避免了加锁操作，提高并发性能。既然是基于多版本，则快照读可能读取到的并不一定是数据的最新版本，而有可能是之前的历史版本。

MVCC 具体则是由 2个隐式字段，undo 日志，Read View 实现的。

InnoDB 中的每行记录除了用户定义的字段外，还有隐式定义的 DB_ROW_ID, DB_TRX_ID, DB_ROLL_PTR 字段

- DB_TRX_ID
  6 Byte，记录着创建/最后一次修改该记录事务ID
- DB_ROLL_PTR
  7 Byte，回滚指针，指向这条记录的上一个版本的 undo 日志（存储于 rollback segment）

由回滚指针和 undo 日志共同组成了一个单向链表，形成了该记录的版本链。

Read View 是事务进行快照读操作时产生的读视图，在该事务执行快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的 ID。它包含三个属性：

- trx_list
  维护 Read View 生成时刻系统正活跃的事务ID的集合
- min_trx
  trx_list 中最小的事务ID
- next_trx
  Read View 生成时刻系统尚未分配的下一个事务ID，也就是已分配的最大事务ID + 1

如果记录的 DB_TRX_ID < min_trx 则说明该记录是生成快照之前事务提交的记录可以直接读取。
否则如果 DB_TRX_ID >= next_trx 则说明该记录是生成快照之后事务提交的记录，则对当前事务不可见。
否则判断 DR_TRX_ID 是否在活跃事务中，如果在则代表生成快照时该记录还未 Commit，对当前事务不可见。
否则可以读取。

事务隔离级别 RC 和 RR 快照读的区别是，RC 的每次快照读操作都会生成一个 Read View，RR 是在第一次快照读时生成 Read View。

在 RR 的隔离级别下，InnoDB 使用 MVCC 和 next-key locks 解决幻读，MVCC 解决的是**快照读**的幻读，next-key locks 解决的是当前读情况下的幻读。

## lock

### latch

latch 一般为闩锁（轻量级锁），在 InnoDB 中 latch 又分为 mutex（互斥锁）和 rwlock（读写锁）。

## Partition

如果数据库是读多写少的场景，可以采用主从模式的方案。冗余数据即提供了可靠性的保障，当主节点发生故障时结合领导选举机制可以快速进行故障转移。从节点又能提供查询服务以提高读负载的能力。

但随着数据规模增长，每个节点因为冗余存储着全量数据。假设单表存有上亿条记录，如果没有命中索引而产生的全表扫描，因此在查询上产生性能瓶颈，需要将数据进行分片。同时，因为只有主节点处理数据的写入，无法进一步提升写负载的处理能力。

什么时候进行分表？
单表数据量较大，mysql 实例的负载并不高时；MySAIM 引擎基于表锁，提高并发能力

什么时候进行分库？
mysql 实例负载较高，或需要扩展读/写负载能力时，可以考虑分库

### 垂直拆分

垂直拆分是按业务分库，例如电商系统中可以拆分为用户库、商品库、订单库，拆分后多个 RDB 实例可以提供并发写入的负载能力。

优点：

- 实现方案简单，仅根据业务边界进行拆分。
- 拆分后业务清晰，降低模块间耦合度
- 多个库实例能提供并发查询/写入能力

缺点：

- 单表数据较大依然会带来的性能问题
- 需要引入分布式事务
- 无法执行跨库连接查询

解决办法：

- 冗余字段，适当的冗余字段可以减少连接查询的诉求，但需要注意数据的一致性
- 冗余表，一些基础表可以在每个库中存放一份
- 应用层组装，通过单表查询在应用层组装

### 水平拆分

#### 为什么单表数据量上千万会存在性能瓶颈？

如果是能利用到索引的等值或范围查询，可以明确扫描区间和边界条件，只需要从磁盘加载少量的页就能完成查询。
如果无法利用索引而执行全表扫描时，尽管符合条件的记录所占不足一页，但依旧需要扫描全部的页来完成查询。随着数据规模增大，时间成线性增长。并且由于单个节点内存资源有限不足以容纳全部数据时，会产生大量的磁盘IO加载和脏页冲刷影响数据库性能，还有可能会影响到内存中的热点数据集，即使内存足够容纳全部数据，内存利用率也很低。
另外数据库在执行查询时是单线程运行的，无法利用到并发计算所带来的优势，在较大的数据集下性能有所下降。

因此可以将数据拆分到多库多表，将 CPU, IO 任务分配到多个节点执行以提供并发能力，每个节点分配合理的内存和数据集，以保证热点数据集带来的性能优势。
同样，数据分片在解决以上的问题也带来了更多的问题，例如：需要根据查询条件将查询路由到相应节点，对查询结果进行合并、排序、计算、过滤，这些操作需要在应用层完成；Limit 查询需要从每个节点获取到足够的记录，合并后再过滤；无法进行 Join 查询，需要冗余表；为了保障事务需要引入分布式事务，而分布式事务也带来一定的开销和吞吐量的降低；扩容时数据迁移带来的问题；无法使用数据库的自增标识；

优点：

- 单表数据量较少，提供了较好的稳定性和负载能力
- 并行全表扫描的能力
- 切分表结构相同

缺点：

- 范围查询需要进行跨库跨表，对数据聚合排序
- limit 查询需要根据条件在每一张表都取到全部数据，聚合排序后再取一定量的数据
- 排序查询，如果分片策略是无序的，需要应用层聚合结果再排序
- 扩容时数据迁移带来的问题
- 无法进行 join 连表查询
- 无法使用本地事务
- 无法使用数据库自增标识

### 分区键的选择

分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题，最近的分片策略为范围分片，枚举分片，一致性Hash分片，这几种分片都有利于扩容

- RANGE
  从0到10000一个表，10001到20000一个表；
- HASH取模
  一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。
- 时间
  按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。
- hash solt, 一致性哈希

这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等，则他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤，比较好的方案是，当前活跃的数据，采用跨度比较短的时间段进行分片，而历史性的数据，则采用比较长的跨度存储。

记录的事务聚集性，可以一定程度避免事务问题。

基因法

事务支持：我们是将整个订单领域聚合体切分，维度一致，所以对聚合体的事务是支持的。

根据业务标识，用户标识，时间维度

可以取模分片、范围分片、hash 取模、hash 环

主要考虑数据的均衡性，热点数据，数据扩容迁移的问题

如果 SQL 语句包含分片键能路由到正确的数据库节点最好

分片会带来 join、分组、排序的问题

#### 其它维度查询

- 异构索引
  建立异构索引
  建立异构数据
  建立异构到库的索引
- 缓存映射法
  把映射关心放在缓存里性能更佳，映射关系不会更改，缓存命中率高
- 基因法
- 冗余法

基于聚合的分片，同一聚合的数据存在相同的分片上。

#### 异构索引表

即采用异步机制将原表的每一次创建或更新，都换另一个维度保存一份完整的数据或索引表。用空间换时间

#### 排序、聚合、过滤

### 数据迁移

采用同步双写或异步双写的方案实现

### 实现方案

- Mycat
- sharding-jdbc
- PingCAP TiDB
- 阿里云 DRDS
- 阿里 Cobar

## Optimize

### 索引优化

#### 哈希索引优化

例如需要存储大量的 URL，并需要根据 URL 进行搜索查找。

新增一个被索引的 url_crc 列，使用 CRC32 做哈希，可以使用条件 url_crc=CRC32('url')。

这样做的性能会非常高，因为 MySQL 优化器会使用这个选择性很高而体积很小的索引来完成查找。

## FAQ

- Mysql 有看过相关的实现吗？Mysql有哪些存储引擎？
  InnoDB, MyISAM, Memory
- InnoDB 设计的优点？
  InnoDB 作为 MySQL 底层的存储引擎，把数据依照主键大小有序的存储在聚集索引中，结合 B+Tree 针对 IO 优化的索引数据结构，提供优秀的查询性能。
  并且提供事务能力的支持，基于 MVCC 实现高性能的并发读写能力。
- 数据库锁有了解过吗
  Mysql 数据库分别有表锁、页锁和记录锁。表锁的开销小，不会发生死锁，锁冲突概率高，并发度最低。
  MyISAM 存储引擎只支持表锁，在执行查询语句前会给所有涉及的表加读锁，执行更新操作前会自动给涉及的表加写锁。读共享，读写互斥，写互斥。
  InnoDB 存储引擎支持记录锁，对数据进行修改或锁定读的时候会对记录加 Record 锁。
  在 RR 级别及以上，如果对范围条件或非唯一索引的修改时会上 gap 锁 和 next-key 锁。
- Mysql 数据隔离有哪几种，它们分别解决什么问题？
  RU, RC, RR, Serial
  RC 解决脏读，RR 解决不可重复读，InnoDB 在一定程度上避免了幻读，Serial 解决幻读
- 你能讲一下 MVCC 的原理吗？
- MVCC 的实现过程？
  MVCC 是通过行记录的隐式列，undo日志，Read View 实现的。
- 数据库索引的效率是如何保证的？
  通过 B+Tree 针对 IO 优化的索引结构，类似二叉树的查找算法近似log(n)的时间复杂度，提供性能稳定的高效查询性能。
- B+Tree 和 Hash 索引的区别？
  两种索引的结构不同，B+Tree 是有序的平衡多叉树，Hash 是键值 key 通过 hash 映射找到 bucket 桶，数据的排列是无序的。
  - hash 索引不能进行范围查询
  - hash 索引不支持联合索引的最左匹配原则
  - hash 索引不支持排序操作
  - hash 索引不支持模糊查询
  - hash 索引在等值查询比 B+Tree 效率更高
- 两种索引分别适用于什么场景？
  hash 索引适用于唯一性高、数据较大的等值查询，B+Tree 适用于范围查询、模糊查询、排序操作，适用性更广
- SQL 优化比较难优化的场景？随便说两个场景。

- 假如数据库是 Int 类型，查询使用单引号的字符串，会走索引嘛？
  数据类型的隐式转换无法使用索引
- 无法使用索引的场景
  - 复合索引，不满足最左原则
  - 复合索引，范围查询之后的键无法使用索引
  - 模糊查询，以%开头的条件
  - 索引列在表达式或函数中
  - 类型不符需要隐式转换的条件
  - 使用索引比全表 cost 更高
  - 用 or 条件且无法利用索引合并
- Java String 类型会转换为 JDBC 的什么类型
  varchar 或 longvarchar
- In 条件传很多值的时候会走索引嘛？怎么解决？
  IN 条件超过 eq_range_index_dive_limit（5.6默认20，5.7默认 200）个值时，会放弃 index dive（索引推导）的方式使用 index statiscs 预估。如果 cost 超过全表扫描则不会使用索引。
  解决方案可以适当调整 eq_range_index_dive_limit 的值，或 force index 强制使用索引。
- 联合索引和覆盖索引有什么区别？
  联合索引是由多个列构成的索引，根据最左原则从小到大的顺序排列。
  覆盖索引是指只需要在一颗索引树上就能获取SQL所需的所有列数据，就无需回表查询。

- Mysql 需要存储一个亿的数据，不能做分库分表，去设计表、索引结构怎么去设计？
- 索引方面怎么去优化呢？具体针对这个需求怎么优化？
- 分库分表的方案如何设计？从哪些方面去选型和设计？
- 实践过程中有用过吗？用什么组件？
- 现在分库分表有一些开源的工具有用过哪些？
- 业务场景假设单表数据达到上亿级别，如何保证它的性能？
  数据分片，选择合理的分片键避免联合查询的问题。
- 分区键如何选择？
- 数据分片后，如何应对复杂查询？
  1. 不建议对分片的数据做复杂查询，通过简单的查询在应用内做聚合逻辑。
  2. 通过代理中间件，对应用透明。
- 即使通过代理查询效率也很低，有没有更好的方案继续优化？数据是散乱的
  根据查询条件，客户端根据算法将查询路由到相应的节点上。
- 现在有很多条业务线，它们都有分库分表的需求，MyCat，SharedJDBC，无论是代理还是Client方式，都可以帮你做分库分表，你要选择你的分片方式。假设使用 SharedJDBC，使用用户标识去做分片，其它查询条件就会比较慢。这种情况下怎么解决问题？
  为其它条件建立到用户标识的索引。
- 如果数据规模达到上亿级别，那么二级索引也会存在大量的数据，怎么优化它的存储结构呢？假设是订单+姓名作为条件
  记录用户到分区的映射，能减少存储量，但扩容时需要重新计算。
  数据根据键值大小有序的分布在多个节点中存储，通过二分法快速查找，适用于范围查询
  计算键值的 hash 取模定位到相应的节点上，或一致性hash算法
  通过映射关系规则，时间换空间的方式减少存储量。
- 思路肯定是这个思路，难点是怎么把二级索引达到查询效率比较高
- 分片后随着数据持续增加，数据迁移的问题？
- 表最大得数据达到多少？如何优化？
- 分表分库的中间件 shared-jdbc、MyCat ，针对索引分片以后分页查询怎么办？
- 基于租户的分片，如果想降低未来再遇到瓶颈，分片的策略有什么考量的？
- 分表后单表容量依然达到上限了需要扩容，如何减少扩容的迁移，停机等资源的投入

- MySql 从哪些方向优化，开放性问题？
  ？索引命中、分表分库、索引优化
  根据统计数据查看索引的唯一性
  查询条件所涉及的索引较多，导致查询优化器分析过慢
  in 条件值较多，基于统计数据的 cost 不准确，导致无法利用索引
- 数据库调优做了哪些工作？
- 简单说一下索引优化和配置优化？能不能讲一下索引优化的例子
  缓冲池，系统文件句柄数量
- Mysql 使用是当作检索来用的嘛？是不是继续适合用 Mysql 数据库
- Mysql 你都知道哪些性能优化的措施？
  查询语句、索引优化、结构优化、服务器配置、读写分片。
- SQL 优化工具你都知道哪些？像 AQPLAN 这些
- 做了服务拆分之后，还会用很多连表查询码？
- 索引优化做了哪些事情？
  首先就考虑索引优化吗？不是应该分析一下，是需要拆表还是没有命中索引。
- 可以将一个具体的索引优化的例子吗？
- 会遇到没有匹配到索引或者新建索引的情况吗？（对方感觉没有实践经验）怎么样新建索引，比如联合索引的例子。
- 比如有字段 a、b、c，使用的条件顺序是 c、b、a，索引会匹配上吗？如果是 c、b 会匹配上吗？ 如果是 c、a 会匹配上吗？
- Mysql 为什么会遇到千万级数据变慢的困惑？
- 如何优化 `SELECT * FROM T ORDER BY key1 LIMIT 5000, 1` 语句的查询效率？
  由于执行实际查询是 server 向 innoDB 依次获取 5001 条记录，并在 server 层过滤掉前 5000 条记录，甚至使用索引的 cost 比较大转而使用全表扫描+filesort的方式执行，因此查询效率比较低。
  可以优化语句为 `SELECT * FROM T, (SELECT id FROM T ORDER BY key1 LIMIT 5000, 1) AS D WHERE T.id = D.id`，因为子查询只有 id 列，可以完全利用二级索引完成查询，避免大量的回表操作，因最终结果只有一条，再通过主键到聚簇索引中获取完整记录。
- 如何限制 SQL 查询时间（全局，局部，底层 JDBC）  
  - 局部: mybaits `statement-timeout=0s`
  - 全局: mybaits `default-statement-timeout=0s`
  - 驱动: JDBC `socketTimeout=0ms`
- 如何做到 mysql 主从切换的时候对业务无感知
- 数据库读写分离怎么实现的？
- 数据库有没有接触过分表分库？
