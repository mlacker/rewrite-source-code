# Cache

## 缓存

### 一致性

更新缓存或更新数据的时候无法做到原子性的同时更新两边的数据，因此在并发读写或第二步操作异常时会遇到各种数据不一致的问题。
如何解决并发场景下的双写一致性问题。

1. 先更新数据
2. 删除缓存（事务范围内）
3. 双删缓存，加入异步队列重试保障删除操作成功。
4. 缓存增加过期时间（最终一致性）

缓存更新的模式有四种：

- Cache aside：查询先查缓存，没有则查询数据库，然后加载至缓存内；更新先更新数据库，然后让缓存失效；或者先失效缓存再更新数据库。
  实现简单，但需要维护两个数据存储。
  - 为了避免并发场景下，多个请求同时更新同一缓存导致脏数据，因此不能直接更新缓存而是令缓存失效。
  - 先更新数据库后失效缓存：并发场景下，推荐使用延迟失效（写请求后给缓存设置1s过期时间），在读请求缓存数据时若 redis 内已有该数据（其它写请求还未结束）则不更新。当redis内没有该数据的时候（其他写请求已令该缓存失效），读请求才会更新redis内的数据。这里的读请求缓存数据可以加上失效时间，以防第二步操作异常导致的不一致情况。
  - 先失效缓存后更新数据库：并发场景下，推荐使用延迟失效（写请求开始前给缓存设置1s过期时间），在写请求失效缓存时设置一个1s延迟时间，然后再去更新数据库的数据，此时其他读请求仍然可以读到缓存内的数据，当数据库端更新完成后，缓存内的数据已失效，之后的读请求会将数据库端最新的数据加载至缓存内保证缓存和数据库端数据一致性；在这种方案下，第二步操作异常不会引起数据不一致，例如设置了缓存1s后失效，然后在更新数据库时报错，即使缓存失效，之后的读请求仍然会把更新前的数据重新加载到缓存内。
  - 设置缓存失效时间，保证最终一致性。
  - 双删缓存，并且在第二次加入到异步队列用重试保证一定能执行成功。
- Read Through：在查询操作中更新缓存，即当缓存失效时，Cache Aside 模式是由调用方负责把数据载入缓存，而 Read Through 则用缓存服务自己来加载。
- Write Through：在更新数据时发生，当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后由缓存自己更新数据库。
  同步操作，只需要维护一个数据存储（缓存），但是实现起来复杂一些。
- Write behind caching：俗称 write back，在更新数据的时候，只更新缓存，不更新数据库。缓存会异步地定时批量更新数据库。
  数据持久化操作时异步的，优点是内存操作速度快，多次操作可以合并。缺点是数据可能会丢失。

缓存本身就是通过牺牲强一致性来提高性能，因此使用缓存提升性能，就会有数据更新的延迟性。

### 可靠性

### 缓存故障

#### 缓存雪崩

Redis 中大量的 key 几乎同时过期，导致大量的并发请求到数据库。

- 随机延长 key 的过期时间，避免同一时间过期
- 延长热点 key 的过期时间或者设置永不过期
- 后台线程定时更新缓存

#### 缓存击穿

热点 key 失效，导致大量并发请求到数据库，负载压力骤增。

- 热点 key 永不过期
- 后台线程定时更新缓存
- 利用 DCL 双重检查锁保证同一时刻只有一个请求可以查询数据库，缓存至 redis 内减少无效负载

#### 缓存穿透

指大量请求或恶意攻击访问不存在的数据时，绕过 redis 访问数据库造成负载。

- 缓存空数据
- 接口访问过滤，如参数合法性校验、用户校验、频率限制
- 布隆过滤器，判断 key 是否存在数据库中。虽然会产生误判，但可以屏蔽绝大部分请求

#### 缓存预热

系统上线时或 Redis 故障重启后，缓存内还没有数据，如果并发量很大则都落到数据库中。

- 根据统计预估热点数据，通过批任务进行预热
- Sentinel 预热限流

#### 缓存更新

更新缓存或更新数据的时候无法做到原子性的同时更新两边的数据，因此在并发读写或第二步操作异常时会遇到各种数据不一致的问题。

## Redis

单机约 130k QPS/s，受 CPU 主频，内存，网络影响。

### Red Lock

对于单实例只需要这个命令即可。

```redis
SET key random NX PX ttl
```

可以通过以下 lua 脚本实现锁释放：

```lua
if redis.call("get", KEYS[1]) == ARGV[1] then
  return redis.call("del", KEYS[1])
else
  return 0
end
```

设置随机值主要是为了防止锁被其它客户端删除。有这么一种情况：

1. A 获得了锁，还没有执行结束，但锁超时自动释放了；
2. B 此时过来，是可以获得锁的，加锁成功；
3. 此时，A 执行结束了，要去释放锁。如果不对比随机值，就会把 B 的锁给释放了；

如何保障可靠性？

即使使用主从结构，也是存在巧合的。在 master 将锁同步到 slave 之前，master 宕掉了，安全失效。

如果可以接受这种小概率的错误，那么这样的主从模式也可以使用。

使用 Red Lock，提供多个 redis 实例，通常使用 5个节点。使用 set 命令分别到 5个节点获取锁，如果 (N / 2) + 1 个节点返回成功，且使用时间 < 锁失效的时间，则加锁成功。否则，撤销锁。

锁可用时间 = 获取锁成功的时间 - 开始获取锁的时间。

如果业务代码执行时间超过了锁的超时时间怎么办？

通常要设置锁有效时间远大于锁使用的时间，如果没有办法避免这种情况。可以开启一个定时线程主动更新锁的 ttl，当业务代码执行完毕后关闭定时器。这里注意避免业务代码异常退出，导致的死锁情况。可以通过 final 或定时线程最大执行次数来保障。
