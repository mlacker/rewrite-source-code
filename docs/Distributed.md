# Distributed

## 理论

### CAP

CAP 原则又称 CAP 定理，指的是在一个分布式系统中 Consistency（一致性), Availability（可用性）, Partition tolerance（分区容错性）三者不可兼得。

- 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。
- 可用性（A）：
- 分区容忍性（P）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。

> Consistency: all nodes see the same data at the same time.
> Availability: Reads and writes always succeed. 即服务一直可用，而且是正常响应时间。
> Partition tolerance: the system continues to operate despite arbitrary message loss or failure of part of the system.

![CAP 理论](https://www.hollischuang.com/wp-content/uploads/2016/03/scenario2_thumb.png)

假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？

有二种选择，第一，牺牲数据一致性，保证可用性。响应旧的数据V0给用户；

第二，牺牲可用性，保证数据一致性。阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。

这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。

### BASE

BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。

BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。

## 服务发现

测试网络故障下 eureka，nacos，zookeeper 的行为

## 负载均衡

## 熔断

## 降级

### 服务降级

### 请求降级

### 缓存降级

指当访问量剧增，服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，即使是有损部分其它服务，仍然需要保证主服务可用。可以将其他次要服务的数据进行缓存降级，从而提升主服务的稳定性。

## 限流

### 固定窗口计数

记录首个请求的开始时间，在限定时间区间内的请求统计。若超过区间则开启新一轮统计。

实现最简单的模型，缺乏实时性和准确性，假设限定 10s 不能超过 100 个请求，前 9s 没有任何请求，第 10s 和下一个时间周期的 11s 分别进入 100 个请求，则服务器在 2s 内瞬间接收到 200 个请求，超过服务器负载。

### 滑动窗口计数

把时间以一定比例分片，统计分片单位时间内的请求量。窗口包含多个时间分片，并且随着时间向前滚动，对窗口内的分片进行求和。

低粒度的时间分片一定程度解决了固定窗口存在的问题。

实时性则是对性能和准确性的衡量，在规定的时间窗口内要求任意刻（瞬态）的请求总量不超过要求则需要实时计算能力，开销相对较大。而通过时间片段的统计，并缓存历史片段的结果则减少了计算量，虽然也降低了实时性和准确性。

其次，在高并发的系统中，并非要求十分精确的限制。而且，流量的计量也要附有时间单位才有意义。

### 信号量计数/线程池

限制同一时间的最大请求数量，根据请求时间长短与吞吐量成反比。

### 桶算法

往桶中以任意的速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶的容量是不变的，保证了整体的速率。

以一定的速率输出请求，限制流量不会超过该速率，有整流的效果。

### 令牌桶

以固定的速率生成令牌，在请求处理之前需要获取一个令牌，请求处理完毕后将这个令牌丢弃。

允许在规定时间内的突峰流量，随后的流量则根据令牌的生成速率限制，若流量较少时可以累积令牌。

Guava 的 RateLimiter 提供了令牌桶算法实现：平滑突发限流（SmoothBursty）和平滑预热限流（SmoothWarmingUp）实现。

## 监控

### 性能指标

如何实现 RT 统计

### 负载

### 告警

## 后备方案

## 分库

### 数据源

- 编码层：逻辑判断
- 框架层：框架支持或拦截器
- 驱动层：ShardingJDBC
- 代理层：MySQL Router
- 服务层：MySQL Cluster, MariaDB

### 跨库分页

- 全局视野
- 禁止跳页查询
- 允许数据精度损失
- 二次查询（第一次查询获取最小条件）

### 海量数据分页

选择唯一有序的索引过滤查询，例如 id。
页码分组：
以一段页码作为一组，每一组内数据的翻页采用ID 偏移量 + 少量的 skip 操作实现。
db.articles.find({ _id: { $lt: start_offset } }).sort({_id: -1}).skip(20*8).limit(1)

## 其它

首先对目标系统进行测量，负载测试、压力测试。明确系统的各环节的性能指标，吞吐量、延时，以及资源负载情况。针对薄弱环节进行优化。
并且预估容量，尤其是高峰期的负载进行容量规划。应用熔断和限流避免服务雪崩现象，识别关键业务和非关键业务，必要时可以降级非关键业务以保障关键业务的运行。最后要做好后备方案的应急措施。

### 分析

分析目标应用类型属于 CPU 密集型、IO 密集型，

读写分离用于读密集型应用
数据分片用于写密集型应用

### 微服务架构和单体架构的区别

单体架构中多个模块包含在一个应用中，

- 结构简单清晰，开发成本低
- 避免了分布式的治理和问题

微服务架构

- 模块的边界清晰，低耦合，职责单一
- 模块可以独立的伸缩
- 模块的升级不影响其它模块
- 模块的故障不影响其它模块
- 可以使用异构技术栈
- 数据库相互独立，垂直分割，提升写负载能力

### TODO

研究限流框架实现

- Hystrix
- Sentinal
- RateLimiter

重试操作

操作的幂等性

基于 hash 分片的数据，在进行扩容时，最好以容量的倍数进行扩容，以减少数据再均衡带来的开销。

## 如何设计一个秒杀系统

### 秒杀系统的关键点

秒杀系统其实主要解决2个问题，一个是并发读，一个是并发写。

- 高性能。 秒杀涉及大量的并发读和并发写，因此支持高并发访问这点非常关键。本文将从设计数据的动静分离方案、热点的发现与隔离、请求的削峰与分层过滤、服务端的极致优化这 4 个方面重点介绍。
- 一致性。 秒杀中商品减库存的实现方式同样关键。可想而知，有限数量的商品在同一时刻被很多倍的请求同时来减库存，减库存又分为“拍下减库存”“付款减库存”以及预扣等几种，在大并发更新的过程中都要保证数据的准确性，其难度可想而知。
- 高可用。 虽然介绍了很多极致的优化思路，但现实中总难免出现一些我们考虑不到的情况，所以要保证系统的高可用和正确性，我们还要设计一个 PlanB 来兜底，以便在最坏情况发生时仍然能够从容应对。

#### 1.设计秒杀系统时应该注意的5个架构原则

- 数据要尽量少。 所谓“数据要尽量少”，请求的数据包括请求包体和返回包体，字段精简。不管是请求数据还是返回数据都需要服务器做处理，而服务器在写网络时通常都要做压缩和字符编码，这些都非常消耗 CPU，所以减少传输的数据量可以显著减少 CPU 的使用。数据库也容易成为一个瓶颈，所以和数据库打交道越少越好，数据越简单、越小则越好。
- 请求数要尽量少。 这里的请求数包括了页面依赖的 CSS/JavaScript、图片、加载这些文件都需要建立连接要做三次握手，另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析，可能会耗时更久。所以，减少请求数可以显著减少以上这些因素导致的资源消耗。
- 路径要尽量短。 所谓“路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数。所以缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时（可以减少网络传输耗时）。要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用，也就是同一个服务同一个web容器。
- 依赖要尽量少。 所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖。比如说你要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。防止强依赖被弱依赖拖垮，比如优惠券服务无法提供优惠券列表，导致拖垮支付服务是不行的
- 不要有单点。 单点是系统架构的大忌，单点意味着没有备份，风险不可控，设计分布式系统最重要的原则就是“消除单点”。避免单点关键点是避免将服务的状态和机器绑定，即服务无状态化，这样服务就可以在机器中随意移动。

#### 2. 动静分离

#### 3.如何有针对性的处理好系统的“热点数据”

数据的访问存在热点，20%的数据占用80%的访问流量，这20%数据就是热点数据。

构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点 Key，如 Nginx、缓存、RPC 服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。

- 业务隔离。 把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。
- 系统隔离。 系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。
- 数据隔离。 秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01% 的数据有机会影响 99.99% 数据。

#### 4.流量削峰应该怎么做

我们知道服务器的处理资源是恒定的，你用或者不用它的处理能力都是一样的，所以出现峰值的话，很容易导致忙到处理不过来，闲的时候却又没有什么要处理。但是由于要保证服务质量，我们的很多处理资源只能按照忙的时候来预估，而这会导致资源的一个浪费。

削峰的存在，一是可以让服务端处理变得更加平稳，二是可以节省服务器的资源成本。针对秒杀这一场景，削峰从本质上来说就是更多地延缓用户请求的发出，以便减少和过滤掉一些无效请求。

流量削峰的一些操作思路：排队、答题、分层过滤。这几种方式都是无损（即不会损失用户的发出请求）的实现方案。

- 排队：用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送
- 分层过滤：在不同的层次尽可能地过滤掉无效请求，让“漏斗”最末端的才是有效请求。而要达到这种效果，我们就必须对数据做分层的校验。分层过滤非常适合交易性的写请求，比如减库存或者拼车这种场景，在读的时候需要知道还有没有库存或者是否还有剩余空座位。但是由于库存和座位又是不停变化的，所以读的数据是否一定要非常准确呢？其实不一定，你可以放一些请求过去，然后在真正减的时候再做强一致性保证，这样既过滤一些请求又解决了强一致性读的瓶颈。

其实还可以采用业务手段来达到一定效果，就像12306分时段发放各个热点城市的票。

#### 7. 兜底方案

![arch](https://img-blog.csdnimg.cn/20181229153209156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpYnJhX3Rz,size_16,color_FFFFFF,t_70)

- 架构阶段：架构阶段主要考虑系统的可扩展性和容错性，避免单点
- 编码阶段：编码保证代码的健壮性，例如涉及远程调用问题时，要设置合理的超时退出机制，防止被其他系统拖垮，也要对调用的返回结果集有预期，防止返回的结果超出程序处理范围，最常见的做法就是对错误异常进行捕获，对无法预料的错误要有默认处理结果。
- 测试阶段：测试主要是保证测试用例的覆盖度，保证最坏情况发生时，我们也有相应的处理流程。
- 发布阶段：发布时也有一些地方需要注意，因为发布时最容易出现错误，因此要有紧急的回滚机制。
- 运行阶段：运行时是系统的常态，系统大部分时间都会处于运行态，运行态最重要的是对系统的监控要准确及时，发现问题能够准确报警并且报警数据要准确详细，以便于排查问题。
- 故障发生：故障发生时首先最重要的就是及时止损，例如由于程序问题导致商品价格错误，那就要及时下架商品或者关闭购买链接，防止造成重大资产损失。然后就是要能够及时恢复服务，并定位原因解决问题。
为什么系统的高可用建设要放到整个生命周期中全面考虑？因为我们在每个环节中都可能犯错，而有些环节犯的错，你在后面是无法弥补的。例如在架构阶段，你没有消除单点问题，那么系统上线后，遇到突发流量把单点给挂了，你就只能干瞪眼，有时候想加机器都加不进去。所以高可用建设是一个系统工程，必须在每个环节都做好。

那么针对秒杀系统在遇到大流量时，应该从哪些方面来保障系统的稳定运行，所以更多的是看如何针对运行阶段进行处理，这就引出了接下来的内容：降级、限流和拒绝服务。

- 降级
    所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务。它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。

    降级方案可以这样设计：当秒杀流量达到 5w/s 时，把成交记录的获取从展示 20 条降级到只展示 5 条。“从 20 改到 5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。

- 限流
    如果说降级是牺牲了一部分次要的功能和用户的体验效果，那么限流就是更极端的一种保护措施了。限流就是当系统容量达到瓶颈时，我们需要通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施。

5）服务降级处理，除了上面讲到的限流和熔断控制，我们还设定了降级开关，对于首页、购物车、订单查询、大数据等功能都会进行一定程度的服务降级，例如我们会对首页原先动态生成的大数据页面布局降级为所有人看到的是一样的页面、购物车也会降级为不在一级页面的tabbar上的购物车图标上显示商品数量、历史订单的查询也会提供时间周期较短的查询、大数据商品推荐也会提供一样的商品推荐，通过这样的降级处理能够很好的保证各个系统在大促期间能够正常的提供最基本的服务，保证用户能够正常下单完成付款。

后端限流：秒杀的时候肯定是涉及到后续的订单生成和支付等操作，但是都只是成功的幸运儿才会走到那一步，那一旦100个产品卖光了，return了一个false，前端直接秒杀结束，然后你后端也关闭后续无效请求的介入了。

我们的方案其实也很简单实时库存的扣减在缓存中进行，异步扣减数据库中的库存，保证缓存中和数据库中库存的最终一致性。

在这个方案中我们使用的分布式缓存是redis，使用了codis集群方案稳定性和高可用方面还是比较有保证的，因为redis是单线程写，所以也不用担心线程安全的问题，redis自身就能够保证数据的强一致性，在下单的事务中包含了实时扣减缓存中的库存和异步发送队列，由队列处理器再异步从队列中取出订单根据订单信息扣减库存系统数据库中的商品数量。

#### 分布式限流

如100万用户来抢100个资源，其实有90%的用户请求是无效的，因为只有100个商品，也只有100个人能够买到。那100万个用户请求过来对系统来说是没有必要的，反而增加了系统压力。其实我们可以只允许5000个用户（业务评估出来的数值）进入业务系统，其他请求的直接返回就行了。

怎么解决？就是利用分布式限流方案，有很多中方案，Nginx限流，业务系统有计数器法，漏斗法，令牌法，网上有很多介绍；一般基于redis进行令牌限流，有很多组件，一般采用google提供的。

#### 异步化

让5000个下单请求进入消息队列，让订单消费服务去慢慢处理5000个请求，这样就有效的把并发同步请求，改为了串行异步。

前端要做一个【抢购中。。。】的状态页面，在此页面中定时轮询下单结果。

#### 限流&降级&熔断&隔离

这个为啥要做呢，不怕一万就怕万一，万一你真的顶不住了，限流，顶不住就挡一部分出去但是不能说不行，降级，降级了还是被打挂了，熔断，至少不要影响别的系统，隔离，你本身就独立的，但是你会调用其他的系统嘛，你快不行了你别拖累兄弟们啊。

#### 其它0

那可不可以分布式的在Redis存参与用户的ID 然后同步记录去重 再随机抽100个
（参与用户指秒杀开始后dt时间段内提交请求的用户
然���前端随机丢点请求 再做好反脚本
其实也是公平的 而且应该比“凭手速”更公平 因为如果完全按到达服务器的时间算 有太多用户不可控但短期内不改变的因素会影响成功率 比如网速 设备性能
